---
layout: post
title: Saving bandwidth with Zopfli
comments: true
tags: [Zopfli]
---
Today Jeff Atwood published the article [Zopfli Optimization: Literally Free Bandwidth](http://blog.codinghorror.com/zopfli-optimization-literally-free-bandwidth/), praising the compression algorithm **Zopfli**. Zopfli was created by Google and [published in 2013](http://googledevelopers.blogspot.de/2013/02/compress-data-more-densely-with-zopfli.html):

> The [Zopfli Compression Algorithm](https://code.google.com/p/zopfli/) is a new open sourced general purpose data compression library that got its name from a Swiss bread recipe. It is an implementation of the Deflate compression algorithm that creates a smaller output size compared to previous techniques. [...]
>
> The output generated by Zopfli is typically [3â€“8% smaller](https://zopfli.googlecode.com/files/Data_compression_using_Zopfli.pdf) compared to [zlib](http://en.wikipedia.org/wiki/Zlib) at maximum compression, and we believe that Zopfli represents the state of the art in Deflate-compatible compression. Zopfli is written in C for portability. It is a compression-only library; existing software can decompress the data. Zopfli is bit-stream compatible with compression used in gzip, Zip, PNG, HTTP requests, and others.

Jeff gave Zopfli a try and got [impressive results](http://blog.codinghorror.com/zopfli-optimization-literally-free-bandwidth/):

> In my testing, Zopfli reliably produces 3 to 8 percent smaller PNG images than even the mighty PNGout, which is an incredible feat.

However, Zopfli has one drawback. Its awesome compression ratio comes with a speed penalty, it's [more than **80 times slower** than gzip](http://www.lifehacker.com.au/2013/03/a-look-at-zopfli-googles-open-source-compression-algorithm/).

Because of its slowness Zopfli is not the best choice for compression at runtime. But where it really shines is when it's used for pre-compressed data. A very good candidate are PNG encoded images. There's even a Zopfli encoder for that purpose, **ZopfliPNG**.   

So because of the proclaimed reduction of the size of PNGs, I gave ZopfliPNG a try. First I measured the current size of all PNG images of my site with this PowerShell command:

``` powershell
PS> gci *.png -Recurse | Measure-Object -Sum Length

Count    : 110
Average  :
Sum      : 4775284
Maximum  :
Minimum  :
Property : Length
``` 

That's about **4.6 MiB** of PNGs. Than I let ZopfliPNG re-compress all these files:

``` powershell
gci *.png -Recurse | %{ .\zopflipng.exe -y --lossy_transparent $_.FullName $_.FullName } 
```

A few minutes and 110 files later the command has finished. 56 files have been changed, i.e. ZopfliPNG was able to produce a smaller size for more than half of all images.

The entire size of all PNGs is now this:

``` powershell
PS> gci *.png -Recurse | Measure-Object -Sum Length

Count    : 110
Average  :
Sum      : 3616048
Maximum  :
Minimum  :
Property : Length
```

So from the former 4.6 MiB it went down to **3.4 MiB**, that's a reduction by **26 percent**. Quite impressive for just changing the compression algorithm.